# Preparing data

To prepare the data for processing, the following format should be included in `,picke` files in the `data/processedFiles` folder.

## Package versions

To run the files, certain versions of libraries need to be installed. This includes:
- Python 3.10.13
- pandas\<2.0.0
- networkx 3.1
- torch 2.0.1
- numpy 1.26.0

Full printout (python -m pip list):
`
Package           Version
----------------- ------------
filelock          3.12.4
Jinja2            3.1.2
MarkupSafe        2.1.3
mpmath            1.3.0
networkx          3.1
numpy             1.26.0
pandas            1.5.3
pip               23.0.1
python-dateutil   2.8.2
pytz              2023.3.post1
setuptools        65.5.0
six               1.16.0
sympy             1.12
torch             2.0.1
tqdm              4.66.1
typing_extensions 4.8.0
tzdata            2023.3
`

## Files

Each file is prefixed with its corresponding dataset. Currently, this includes:
- `gowalla_...``
- `global_scale_...``

### File structure

Depending on the file the contents will differ slightly. Here's a breakdown of each file:

#### `PREFIX_allData.pickle`

Contains ~170k rows with the following columns:
- ?, USER, POI, timestamp, lat, lon, countryCode

Where the first column might be the internal userID generated by the original dataset.

#### `PREFIX_beamSearchHashDict.pickle`

Contains mappings from len A to B hashes, starting from 2 -> 3 and ending in 5 -> 6. It is unclear exactly how this is used, but it might be related to the other fiels which are numbered between 2..6. 

#### `PREFIX_data.pickle`

Contains ~130k rows with the same columns as `allData.pickle`. This one might only contain the users/POI's with a certain amount of check-ins. Although this is quite unclear - since the `allData.pickle` already contains a subset of the total rows from the original dataset (which as ~33m check-ins, while `allData.picke` has 170k).

#### `PREFIX_geohash2index_X.pickle`

Similar to the `beamSearchHashDict`, these files contains mappings from 2..6 letter hashes to numbers. Might be related to mappings between the files.

#### `PREFIX_geohash2poi_X.pickle`

Similar to the files above, contains mappings from 2..6 letter hashes to numbers.

#### `PREFIX_globalIndex2latlon.pickle`

Contains dict mappings from keys (numbers) to lat-lon coordinates. This seems to correspond to the POI indexes and their coordinates.

#### `PREFIX_poi2geohash_X.pickle`

Seems to contain reverse mappings compared to the `geohash2poi_X.pickle` files, where X determines the length of the hash that the poi maps to.

#### `PREFIX_poi2index.pkl`

Contains dict mappings from full hashes (ex. 500b09e8e4b0381c845610ee) to numerical values. Likely mappings from the hashes in the original data set to internal IDs used.

#### `PREFIX_poi2timeslotList.pickle`

Contains dict mappings from POI indexnumbers (see previous file) to single/double digit numbers. Unclear exactly what they're used for.

#### `PREFIX_poiCount.pickle`

Contains an integer value for the amount of POI's in the dataset.

#### `PREFIX_spatial.edgelist`

Used to read edge data using NetworkX library. Likely used to map users to POI locations, and vice-versa.

#### `PREFIX_temporal.edgelist`

Used to read edge data using NetworkX library. Likely used to map users to POIs using check-in timestamps.

#### `PREFIX_test.pkl`

Contains an 2D array of lon/lat pairs, unclear exactly how they are grouped or used together.

#### `PREFIX_testData.pickle`

Contains the same structure pandas table as for `allData.pickle`/`data.pickle` files, but with 57k rows. Might've been used during development to test the code.

#### `PREFIX_timeSlot2Index.pickle`

Contains a simple dictionary mapping X -> X+1 for values from 0 to 19.

#### `PREFIX_timeslot2POIlist.pickle`

Contains 20 mappings to POI indexes. Might be a grouping between check-in times to differentiate between times of check in.

#### `PREFIX_train.pkl`

A 3-tuple, each with ~16k entries - which seems to correlate to the amount of users in the filtered data set. Unclear why they are grouped into 3 different entries.

#### `PREFIX_trainPOI.pickle`

Seems to contain all the POI indexes in a single array.

#### `PREFIX_user2index.pickle`

Seems to map the user IDs in the original dataset (integers) to the user indexes used in the filtered data set (~16k mappings).

#### `PREFIX_userCount.pickle`

Contains the amount of users (~16k).

#### `PREFIX_usersData.pickle`

Contains a 2-tuple with ~16k entries each, where each entry is an array with the same ID (which seems to be the user index). Unclear exactly what it is used for.

### Files used by to train/process data

Most of the files are provided to indicate what types of mappings were done to prepare the data, but are not actually used. Therefore, only the following have to exist in order to run `train.py`
- temporal.edgelist
- spatial.edgelist
- userCount.pickle
- _poi2geohash2..6.pickle
- _geohash2poi2..6.pickle
- _geohash2Index2..6.pickle
- _beamSearchHashDict.pickle
- _poiCount.pickle
- _train.pkl
- _usersData.pickle
- _train.pkl
- _test.pkl